{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chefs-kiss/ML_J2026/blob/main/PA3_Classification_with_Fashion_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name:\n",
        "\n",
        "Who you worked with:"
      ],
      "metadata": {
        "id": "BgF31AxdWUdS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objectives\n",
        "The goals of this project are to:\n",
        "- Perform EDA, PCA, and visualize the data\n",
        "- Implement K-means clustering\n",
        "- Evaluate the clustering results against the true labels\n",
        "- Thoughtfully interpret and discuss the results\n",
        "\n",
        "## Overview\n",
        "In this assignment, you will explore the Fashion MNIST dataset, which contains grayscale images of 10 different clothing items. You will focus on applying unsupervised learning techniques, specifically K-means clustering, to see if the algorithm can naturally identify patterns that correspond to different clothing categories. You will also critically evaluate the performance of clustering against the ground truth labels and reflect on the limitations of the algorithm.\n",
        "\n",
        "## Schedule\n",
        "Here is the suggested schedule for working on this project:\n",
        "- Weekend: Read through project instructions, complete Task 0.\n",
        "- Tuesday: Complete Tasks 1-2.\n",
        "- Wednesday: Complete Tasks 3-4.\n",
        "- Thursday: Complete Task 5.\n",
        "\n",
        "This project is due on Thursday, 3/6, by 11:59pm.\n"
      ],
      "metadata": {
        "id": "MiERNejsWYwb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 0: Data Exploration\n",
        "\n",
        "We'll be working with the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset, which contains 70,000 grayscale images of 10 different fashion items.\n",
        "\n",
        "The images show individual articles of clothing at low resolution (28 by 28 pixels), as seen here:\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
        "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "    <b>Figure 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion-MNIST samples</a> (by Zalando, MIT License).<br/>&nbsp;\n",
        "  </td></tr>\n",
        "</table>\n",
        "\n",
        "Fashion MNIST is intended as a replacement for the classic [MNIST](http://yann.lecun.com/exdb/mnist/) dataset. MNIST is often used as the \"Hello, World\" of machine learning programs for computer vision. The MNIST dataset contains images of handwritten digits (0, 1, 2, etc.) in a format identical to that of the articles of clothing you'll use here.\n",
        "\n",
        "Fashion MNIST has more variety, and it's a slightly more challenging problem than regular MNIST. Both datasets are relatively small and are used to verify that an algorithm works as expected. They're good starting points to test and debug code.\n",
        "\n",
        "The dataset we will be using contains 60,000 images to train the model.\n"
      ],
      "metadata": {
        "id": "RFJ0WWzNWwR3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we'll load the data and perform some exploratory data analysis.\n",
        "\n",
        "##Load Data\n",
        "\n",
        "We will be working with a dataset from TensorFlow. This library is one we will come back to when working with neural nets. For now, we only are using it for one of it's datasets."
      ],
      "metadata": {
        "id": "iX5dRctiZvGV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzLKpmZICaWN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will only be using the training dataset since we're doing an unsupervised approach."
      ],
      "metadata": {
        "id": "zx2jVrxfZ-yq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sample image\n",
        "Now, let's visualize an example image from the dataset."
      ],
      "metadata": {
        "id": "tiiYWRrwXFXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display an example image\n",
        "plt.figure(figsize=(3, 3))\n",
        "plt.imshow(train_images[0], cmap='gray')\n",
        "plt.title(f'Label: {train_labels[0]}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nlBJL-BnXB4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##DataFrame\n",
        "\n",
        "We will create a pandas DataFrame so that we can do some initial EDA. Remember that for forming the clusters, we will only use the features. However, we can still use the labels later to evaluate our results.\n",
        "\n",
        "Before we create the pandas DataFrame, we're going to create a huge vector of our data. This is the first step required to get our data into a pandas DataFrame. It is also introduces a helpful method called `reshape`. If you decide to use image data in the future, this method will be very helpful to know."
      ],
      "metadata": {
        "id": "TgV2qlnFXUWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Flatten the images from 28x28 to a 784-dimensional vector to use with our algorithm\n",
        "train_data = train_images.reshape((train_images.shape[0], 28 * 28)).astype(np.float32)\n",
        "\n",
        "# Create a DataFrame to make viewing easier (if necessary for your case)\n",
        "X = pd.DataFrame(train_data)\n",
        "\n",
        "#labels for evaluating clusters later on\n",
        "y = train_labels"
      ],
      "metadata": {
        "id": "ZWSmxWE0XW-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a peak at what this data looks like"
      ],
      "metadata": {
        "id": "Zk85WqnpXwVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.head(3)"
      ],
      "metadata": {
        "id": "q5mFCXfUX69L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each feature is a single pixel in the 28x28 image, with values ranging from 0 to 255. The labels `y` are an array of integers, ranging from 0 to 9."
      ],
      "metadata": {
        "id": "TOmP6FNYX77N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(y[:20])"
      ],
      "metadata": {
        "id": "B_Ryrahwajzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each image is mapped to a single label. Since the class names are not included with the dataset, we're going to store them here to use later when evaluating and plotting our images."
      ],
      "metadata": {
        "id": "ziJLzu0SbEXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "metadata": {
        "id": "WbJp8WinbKt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brm0b_KACaWX"
      },
      "source": [
        "## Explore the data\n",
        "\n",
        "Let's explore the format of the dataset before training the model. The following shows there are 60,000 images, with each image represented as 28 x 28 pixels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zW5k_xz1CaWX"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIAcvQqMCaWf"
      },
      "source": [
        "Likewise, there are 60,000 labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRFYHB2mCaWb"
      },
      "outputs": [],
      "source": [
        "len(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üíª Question1: Is The Data Balanced?\n",
        "\n",
        "Let's take a look at how many of each type of clothing article we have.\n",
        "\n",
        "Below is the dataframe of our target.\n",
        "\n",
        "Add a new line of code that takes `y_df` and finds the counts of each class.\n",
        "\n",
        "Is our dataset balanced?\n"
      ],
      "metadata": {
        "id": "Mb5Mm9t-66JA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_df = pd.DataFrame(y)\n",
        "#add code here"
      ],
      "metadata": {
        "id": "x56wEi2_7II2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###‚úè Question2: Image Flattening\n",
        "\n",
        "Our images are flattened from a 28√ó28 image to 784 features. What spatial information might be lost in this process? How could this impact our clustering results?"
      ],
      "metadata": {
        "id": "i-4g5N0H78CS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PCA\n",
        "\n",
        "It would take a very long time to generate pairplots for 700+ features. Instead, we'll use principal component analysis (PCA) for dimensionality reduction, so that we can visualize a projection of the data. Here, we reduce the data to a few dimensions.\n"
      ],
      "metadata": {
        "id": "DO-0p9FRbddQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=9)\n",
        "pca.fit(X)\n",
        "projection = pca.transform(X)\n",
        "projection_df = pd.DataFrame(projection)"
      ],
      "metadata": {
        "id": "bt6YgBjXaUee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure()\n",
        "sns.pairplot(projection_df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S6CoQEU0afQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###‚úè Question3: PCA plots\n",
        "How do the different shapes of these plots (such as nugget-shaped, normal, or multi-modal) help us understand the characteristics of clothing categories? For example, do they show variations in style within a category, or do they highlight differences between categories?"
      ],
      "metadata": {
        "id": "BfWwZo_hcLBj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1: Closest Centroid\n",
        "\n",
        "First, you'll implement a function that takes an array of data points and an array of centroids, and returns an array giving the index of the closest centroid to each data point. Note that the shapes should be:\n",
        "\n",
        "* `data` has shape $(N, D)$, where $N$ is the number of datapoints and $D$ is the dimensionality of each datapoint.\n",
        "* `centroids` has shape $(k, D)$, where $k$ is the number of centroids, and $D$ is the dimensionality of each datapoint.\n",
        "* `closest_centroids` (the return value) has shape $(N,)$, where $N$ is the number of datapoints.\n",
        "\n",
        "The code below has been outlined in such a way that only basic programming logic needs to be used. You may find that using `numpy` methods helpful when calculating the Euclidean.\n",
        "\n",
        "Hint: since we have high-dimensional data you can use `np.sum((point - centroid) ** 2)` to find the sum of squared differences when you do the distance calculation.\n"
      ],
      "metadata": {
        "id": "PditSd35_ZBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def closest_centroid(data, centroids):\n",
        "    # init to store the closest centroid index for each data point\n",
        "    closest_centroids = []\n",
        "\n",
        "    # looping through each data point\n",
        "    for point in data:\n",
        "        min_distance = float('inf')  #init min distance to huge number like infinity\n",
        "        closest_centroid_index = -1\n",
        "\n",
        "        # counter for centroid index\n",
        "        i = 0\n",
        "\n",
        "        # looping through each centroid to compute the distance to the data point\n",
        "\n",
        "            # calculate the Euclidean distance\n",
        "\n",
        "\n",
        "            # if the distance is smaller than the minimum (min_distance) found so far, update the closest centroid (closest_centroid_index)\n",
        "\n",
        "\n",
        "            # increment the counter by 1\n",
        "\n",
        "        # appending the index of the closest centroid to the result list\n",
        "        closest_centroids.append(closest_centroid_index)\n",
        "\n",
        "    # return the list of closest centroid indices\n",
        "    return np.array(closest_centroids)\n"
      ],
      "metadata": {
        "id": "ZIoMpAjXAqcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code chunks below will test your functions. If you run both and no errors occur, your function works as expected."
      ],
      "metadata": {
        "id": "WKZBto9I4W_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# testing your function\n",
        "data = np.array([[-2,2], [-1, 2], [-1,1], [1,1], [1,2], [2,2]])\n",
        "centroids = np.array([[-3,3], [3,3]])\n",
        "assert(np.array_equal(closest_centroid(data, centroids), np.array([0,0,0,1,1,1])))"
      ],
      "metadata": {
        "id": "nlAUI4Ar_01L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = train_data[:10]  # First 10 images\n",
        "centroids = train_data[121:123]  # Images at index 121 and 123 as centroids\n",
        "closest_centroid(data, centroids)\n",
        "#assert(np.array_equal(closest_centroid(data, centroids), np.array([1, 1, 0, 0, 0, 1, 0, 1, 0, 0])))"
      ],
      "metadata": {
        "id": "FsMhmr55_2vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###‚úè Question4: Dimensionality and Distances\n",
        "\n",
        "In high-dimensional spaces like our 784-dimensional images, how does distance calculation become problematic? (This is related to what we call the \"curse of dimensionality\")"
      ],
      "metadata": {
        "id": "c7zEsOcet3dE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###‚úè Question5: Computational Costs\n",
        "\n",
        "If we apply this function to all 60,000 images, it will be computationally expensive. How might you modify the approach to make it more efficient for large datasets? For example, we may consider only a subset of the data rather than all 60k images."
      ],
      "metadata": {
        "id": "PS8mI0eRt_4i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###‚úè Question6: Dealing with Ties\n",
        "\n",
        "What would happen if two centroids were equally distant from a data point? How does your function handle this case, and is this approach appropriate?"
      ],
      "metadata": {
        "id": "jwg7qCK6uMR2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2: Recompute Centroids\n",
        "\n",
        "Next, you'll define a function that recomputes centroids once each data point has been assigned to a cluster. This function takes an array of datapoints and an array giving the cluster assignments. The index of each centroid should correspond to its cluster number. Note that the shapes should be:\n",
        "\n",
        "* `data` has shape $(N, D)$, where $N$ is the number of datapoints and $D$ is the dimensionality of each datapoint.\n",
        "* `labels` has shape $(N,)$, where $N$ is the number of datapoints.\n",
        "* `centroids` (the return value) has shape $(k, D)$, where $k$ is the number of centroids, and $D$ is the dimensionality of each datapoint.\n"
      ],
      "metadata": {
        "id": "vZl5KQ7bB51M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_centroids(data, labels):\n",
        "    # getting the number of clusters\n",
        "    k = np.max(labels) + 1 #adding one since we start counting at 0 not 1\n",
        "\n",
        "    # init to store the new centroids\n",
        "    new_centroids = []\n",
        "\n",
        "    # looping through each cluster\n",
        "    for i in range(k):\n",
        "        # get the data points(data) assigned to cluster i (check if labels are equal to i)\n",
        "        cluster_points = #\n",
        "\n",
        "        # compute the mean (use np.mean) of the data points in the cluster (cluster_points)\n",
        "        new_centroid = #\n",
        "\n",
        "        # append the new centroid to our new centroid list\n",
        "        new_centroids.append(new_centroid)\n",
        "\n",
        "    # convert new_centroids into a numpy array and return\n",
        "    return #\n"
      ],
      "metadata": {
        "id": "1P4jMAbKEBgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code chunks below will test your functions. If you run both and no errors occur, your function works as expected."
      ],
      "metadata": {
        "id": "ba_JRj3e5EX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# testing your function\n",
        "data = np.array([[-2,2], [-1, 2], [-1,1], [1,1], [1,2], [2,2]])\n",
        "labels = np.array([0,0,0,0,1,1])\n",
        "assert(np.array_equal(compute_centroids(data, labels), np.array([[-.75, 1.5], [1.5, 2]])))"
      ],
      "metadata": {
        "id": "AzpKK0jCCDjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = train_data[:10]  # Take the first 10 images for testing\n",
        "labels = np.array([1, 0, 1, 1, 1, 0, 1, 0, 1, 1])  # Example labels (clusters)\n",
        "assert(np.array_equal(compute_centroids(data, labels)[0][5:7], np.array([0.6666667 , 0.33333334], dtype='float32')))"
      ],
      "metadata": {
        "id": "8-ykHRF9CM_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###‚úè Question7: Centroid as an Image\n",
        "\n",
        "A centroid is the mean of all points in a cluster. For image data, what does this \"average image\" actually represent visually? Would it still look like a recognizable piece of clothing?"
      ],
      "metadata": {
        "id": "KfHeeObLuUev"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###‚úè Question8: Mean vs Median\n",
        "\n",
        "The mean minimizes the sum of squared distances to all points. What if we used the median instead? How might this change our clusters and when might this be beneficial?"
      ],
      "metadata": {
        "id": "R7FCFT_wuckH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3: Implement $k$-Means\n",
        "\n",
        "Now, that you've seen how the various components of the algorithm are created, we're going to switch gears and create a model.\n",
        "\n",
        "Usually when we have a ton of data, we have methods to make it easier on our algorithms (and machines) to create the clusters. For our purposes, we're going to take only three of the types of clothing and do k-means on this subset of data. This will help us as we eventually want to also investigate the clusters to see what is going on.\n",
        "\n",
        "With large data, that also means that the process of choosing the actual best k take a bit of time. Instead, we're going to use some domain knowledge (we're choosing 3 articles of clothing in our subset) and use that to pick our k value."
      ],
      "metadata": {
        "id": "rN1vhTR0Ep9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = np.column_stack((X, y))\n",
        "articles = [y_names.index(\"Coat\"), y_names.index(\"Bag\"), y_names.index(\"Sneaker\")]\n",
        "subset = dataset[np.isin(dataset[:, -1], articles)]\n",
        "X_subset = subset[:, :-1]\n",
        "y_subset = subset[:,-1:]"
      ],
      "metadata": {
        "id": "V5XGFQ1KqAFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "kmeans = KMeans(n_clusters=3, random_state = 42)\n",
        "kmeans.fit(X_subset)\n",
        "silhouette_score(X_subset, kmeans.labels_)"
      ],
      "metadata": {
        "id": "1R00OhAlGI_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###‚úè Question9: Subset Article Choices\n",
        "Our subset currently cointains Coat, Bag, and Sneaker. What if instead we had selected only footwear items: Sandal, Sneaker, Ankle boot? What clustering challenges might arise when items are similar? How might this affect our silhouette score compared to clustering with an unrelated subset?  "
      ],
      "metadata": {
        "id": "jHDRN23mvzpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###‚úè Question10: Silhouette Score\n",
        "\n",
        "The silhouette score measures how well-separated clusters are. What would a perfect silhouette score be, and what does our current score suggest about our clusters?"
      ],
      "metadata": {
        "id": "JBhBCs29wV8I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4: Compare Clusters with Ground Truth\n",
        "Now, we'll compare the clusters found by the k-means algorithm with the true labels of the dataset using a confusion matrix."
      ],
      "metadata": {
        "id": "1rlvo-z0wWvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Compare clusters with true labels\n",
        "pd.crosstab(y_subset.flatten(), kmeans.predict(X_subset))"
      ],
      "metadata": {
        "id": "JyjRso9Jwa4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding particular images\n",
        "\n",
        "You can further invesitgate by using the function below `find_pic` which will take the class label (items from row_0 in the matrix above) and the cluster label (items from col_0 in the matrix above) and return the first image that meets that criteria."
      ],
      "metadata": {
        "id": "9iMDbNAd0Wpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_pic(article_type, cluster_label):\n",
        "  \"\"\"This function takes in y label (article_type) and the cluster it belongs\n",
        "  to (cluster_label) and will show that image\"\"\"\n",
        "  valid_indices = np.where((y_subset.flatten() == article_type) & (kmeans.labels_ == cluster_label))[0]\n",
        "  chosen_index = np.random.choice(valid_indices)\n",
        "  print(chosen_index)\n",
        "  plt.figure(figsize=(3, 3))\n",
        "  plt.imshow(X_subset[chosen_index].reshape(28, 28), cmap='gray')\n",
        "  plt.title(f'Label: {article_type}, Cluster: {cluster_label}')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "7EmJKcfMzUZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_pic(4,0)"
      ],
      "metadata": {
        "id": "_z76okPZkK1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_pic(4,1)"
      ],
      "metadata": {
        "id": "4PfmJwlBkLPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_pic(4,2)"
      ],
      "metadata": {
        "id": "rVYyKfK2kODq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###‚úè Question11: Labels\n",
        "\n",
        "What does the row values 4, 7, 8 mean in the context of our data?"
      ],
      "metadata": {
        "id": "lfr76jTWyVeo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üíª Question12: Identifying Clothing\n",
        "\n",
        "Is the model generally grouping items according to their true class? Which clothing article type seems easiest for the algorithm to identify? Which is most confused? You can use the `find_pic` function above if that is helpful."
      ],
      "metadata": {
        "id": "PuOXh3xGymcV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üíª Question13: Visual Inspection\n",
        "\n",
        "Consider the shapes of our articles of clothing. What visual features might cause the algorithm to group certain articles together despite having different labels? Use the function above to find at least two pieces of evidence in the data to support your claim. Add your code below."
      ],
      "metadata": {
        "id": "k8Rt4hr_yz_7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###‚úè Question14: Clusters\n",
        "\n",
        "For each cluster:\n",
        "* which of the labels appear in the cluster?\n",
        "* is there a label that occurs significantly more frequently than the others?\n",
        "\n",
        "Where does the algorithm have difficulty? Why do you think this is happening?"
      ],
      "metadata": {
        "id": "UkT-ZnRAwnrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reflection\n",
        "\n",
        "Take a moment to reflect on the assingment\n",
        "\n"
      ],
      "metadata": {
        "id": "DxjGD4-O9APK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚úè Question 15: Reflection\n",
        "\n",
        "What did you like about it? What could be improved? Your answers will not affect your overall grade. This feedback will be used to improve future programming assignments.\n",
        "\n"
      ],
      "metadata": {
        "id": "w11OpZPk9Gkw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Grading\n",
        "For each of the following accomplishments, there is a breakdown of points which total to 21. The fraction of points earned out of 21 will be multiplied by 5 to get your final score (e.g. 17 points earned will be 17/21 * 5 ‚Üí 4.05)\n",
        "* (1pt) Task0 q1: Identified counts and discussed if balanced.\n",
        "* (1pt) Task0 q2: Identified at least one concern of flattening images\n",
        "* (1pt) Task0 q3: Discussed distributions of features\n",
        "* (2pt) Task1: Function `closest_centroid` runs as expected\n",
        "* (1pt) Task1 q4: Correctly states why dimensions matter when calculating distances\n",
        "* (1pt) Task1 q5: At least one approach to save on computational costs is discussed.\n",
        "* (1pt) Task1 q6: Discusses ties and offers a solution\n",
        "* (2pt) Task2: Function `recompute_centroid` runs as expected\n",
        "* (1pt) Task2 q7: Correctly explains what \"average image\" means\n",
        "* (1pt) Task2 q8: Discusses mean vs median appropriately\n",
        "* (1pt) Task3 q9: Discusses subsets and their influence on the accuracy of the model\n",
        "* (1pt) Task3 q10: Interprets the silhouette score\n",
        "* (1pt) Task4 q11: Indentifies what each label means in the context of the dataset\n",
        "* (2pt) Task4 q12: Interprets the confusion matrix for articles of clothing (rows)\n",
        "* (1pt) Task4 q13: Used the function `find_pic` to support the claims\n",
        "* (2pt) Task4 q14: Interprets the confusion matrix for clusters (columns)\n",
        "* (1pt) Task5 q15: You have reflected on the assignment"
      ],
      "metadata": {
        "id": "TK0un0zH1c8b"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}